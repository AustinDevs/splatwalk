# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## What This Is

SplatWalk — a static demo site showcasing top-down aerial fly-over of land parcels using Gaussian Splatting. A progressive zoom pipeline generates high-detail overhead splats from drone photos, viewed as an interactive fly-over in the browser. Assets are generated by an ephemeral DigitalOcean RTX 4000 Ada GPU pipeline and hosted on DO Spaces CDN.

## Commands

```bash
npm run dev          # Static file server for local development
```

No build step, no test suite, no linter. Pure static HTML/JS/CSS.

## Project Structure

```
index.html              # Single-mode splat fly-over viewer
js/ground-demo.js       # Top-down splat viewer (Three.js + GaussianSplats3D via importmap)
css/styles.css          # Base styles
scripts/
  run_demo_assets.sh    # Launch GPU droplet to generate demo assets
  setup-volume.sh       # Install runtime onto DO Volume (idempotent)
  cleanup-droplets.sh   # Destroy stale GPU droplets
  gpu/                  # Python scripts that run on the remote GPU droplet
    run_pipeline.sh     # Main pipeline orchestrator
    render_zoom_descent.py  # Stage 3: top-down progressive zoom descent
    compress_splat.py   # Stage 5: pruning + .splat binary conversion
    quality_gate.py     # Confidence scoring
    generate_viewer_assets.py # Demo asset generation (splat + manifest)
```

## How It Works

1. Default view: loads aukerman demo splat from DO Spaces CDN
2. `?manifest=https://...CDN.../manifest.json` overrides with a different asset set
3. CDN assets (DO Spaces) must have CORS configured to allow browser fetch
4. Single mode: Gaussian Splat fly-over (top-down, free camera WASD + Q/E altitude)
5. Requires `crossOriginIsolated` (HTTPS + COEP/COOP headers from hosting platform)

## GPU Pipeline

Scripts in `scripts/gpu/`, fetched from GitHub at runtime for hotfixes. Launched via `scripts/run_demo_assets.sh`.

### Pipeline Stages

1. **Stage 1**: MASt3R geometry initialization (point cloud + camera poses)
2. **Stage 2**: InstantSplat training (10K iterations, aerial splat)
3. **Stage 3**: Top-down progressive zoom descent (`render_zoom_descent.py`)
   - 5 altitude levels: drone → 50% → 25% → 12% → 5% of drone AGL
   - All cameras nadir (looking straight down) — no slerp toward horizon
   - Camera grid tiles scene footprint, FOV narrows at lower altitudes
   - Pure render + retrain loop (no generative enhancement)
   - Retrain 2000 iterations per level with densification enabled
4. **Stage 4**: Quality gate confidence scoring
5. **Stage 5**: Compression (prune + .splat conversion + CDN upload)

### Infrastructure

- **Everything-on-Volume**: Runtime (conda, repos, models) lives on a persistent DO Volume at `/mnt/splatwalk/`. Droplets are stateless — attach Volume at boot, detach on self-destruct.
- `scripts/setup-volume.sh` — Installs full runtime onto Volume (idempotent)
- DO has a **1 GPU droplet limit** — always check/destroy existing before creating new

## Critical Technical Details

### Top-Down Progressive Zoom (Key Design Decision)
The pipeline stays looking straight down at all altitudes. This is fundamentally simpler than generating horizontal ground-level views because:
- The splat only needs to render well from above, which is what it's trained on
- Progressive steps let Gaussian scales adapt gradually
- Pure render + retrain at each level — no generative models in the 3D pipeline
- 2D ortho tiles use Real-ESRGAN (deterministic 2x upscale, no hallucination)

### Uniform Scene Scaling (.splat format)
Positions AND scales must be multiplied by the **same factor** (default 50x). Separate scale multipliers distort trained Gaussian overlap proportions, causing wash-out or speckle. Scene is centered at centroid before scaling.

### InstantSplat Training
- `n_views` is a **path component** (`sparse_{n_views}/0/`), NOT a camera count limit
- `Scene()` always starts from COLMAP, never from checkpoints
- Densification is disabled in Stage 2 — enabled in Stage 3 zoom descent for new detail

### PyTorch3D Compilation
Pre-built pip wheel has CPU-only `_C.so` (~1MB). GPU rasterization requires building from source with both `FORCE_CUDA=1` AND `TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9;9.0"`. Properly compiled `_C.so` is ~24-27MB.

### Web Viewer
- CDN assets require CORS headers from DO Spaces; hosting platform must serve COEP/COOP headers for SharedArrayBuffer
- `computeSceneBounds()` only works for .splat files (reads binary format directly)
- GaussianSplats3D viewer options: `gpuAcceleratedSort`, `antialiased`, `kernel2DSize`, `sphericalHarmonicsDegree` are compile-time (set at construction, not runtime)
- Manifest includes `camera_defaults` with position/look_at for initial top-down view
- WASD moves on XY plane, Q/E adjusts altitude, mouse orbits

### Manifest Format (v2 — Top-Down)
```json
{
  "splat_url": "https://cdn.../scene.splat",
  "viewer_mode": "topdown",
  "scene_bounds": { "min": [...], "max": [...], "center": [...], "size": [...], "ground_z": ... },
  "camera_defaults": { "position": [...], "look_at": [...], "up": [...] },
  "metadata": { "drone_agl_m": 63, "scene_scale": 50, "splat_size_mb": 54 }
}
```

### COLMAP from cameras.json
cameras.json `rotation` field = R_c2w (camera-to-world). To get COLMAP format: `R_w2c = R_c2w.T`, `T_w2c = -R_w2c @ position`.

## Environment

`.env` is used by `scripts/run_demo_assets.sh` (GPU launcher), not by the static site. Key variables:
- `DO_API_TOKEN`, `DO_SPACES_KEY/SECRET`, `DO_VOLUME_ID` — DigitalOcean infra
- `DO_SSH_PRIVATE_KEY_PATH` — SSH key for GPU droplets (default `~/.ssh/splatwalk_gpu`)
- `GEMINI_API_KEY` — Scene captioning (Gemini 2.5 Flash)
- `SLACK_WEBHOOK_URL` — Pipeline progress notifications
- `GPU_DROPLET_SIZE` — `gpu-4000adax1-20gb` (default, $0.76/hr)
